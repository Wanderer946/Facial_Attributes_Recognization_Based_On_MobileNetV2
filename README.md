# Facial_Attributes_Recognization_Based_On_MobileNetV2
A face multi-attribute classification method based on MobileNetV2
## ğŸ§ Overview
This project implements a lightweight, multi-label facial attribute recognition system leveraging the MobileNetV2 architecture. It is capable of classifying multiple attributes (e.g., **gender, expression, pose**, etc.) from facial images with high efficiency. The system is optimized for training and inference on devices with limited computational resources.

The complete pipeline includes **data preprocessing, model definition, training, evaluation, and visualization of results**.
## ğŸ”Workflow
```
graph TD
    A[Original Dataset] --> B[Data Preprocessing & Partition]
    B --> C[Model Construction (MobileNetV2)]
    C --> D[Model Training]
    D --> E[Evaluation & Testing]
    E --> F[Attribute Prediction on New Images]
    D --> G[Visualization with TensorBoard]
```


## ğŸ“¦Prerequisites
Download the project:
```
git clone https://github.com/Wanderer946/Facial_Attributes_Recognization_Based_On_MobileNetV2.git
cd Facial_Attributes_Recognization_Based_On_MobileNetV2
```
### ğŸ› Dependencies
- In conda:
Create the environment with:
```bash
conda env create -f environment.yaml
conda activate face_attr
```
- In pip:
Install dependencies with:
```bash
pip install -r requirements.txt
```
**Key dependencies:**
PyTorch
torchvision
pandas
numpy
Pillow
tqdm
pyyaml
matplotlib

### ğŸ“Dataset
Before starting the train and test, you should decompress the compressed package of the data set in advance:
```bash
unzip Dataset/img/img.zip Dataset/img
```
Your dataset directory should follow this structure:
```bash
Dataset/
â”œâ”€ img/
â”‚  â”œâ”€ 000001.jpg
â”‚  â”œâ”€ 000002.jpg
â”‚  â””â”€ ...
â”œâ”€ list_attr.txt            # Attribute labels
â”œâ”€ list_partition_1000.txt  # Partition files
â”œâ”€ list_partition_2000.txt
â”œâ”€ list_partition_3000.txt
â””â”€ readme.md
```

## ğŸ—‚Project Structure

```
Project_Root/
â”œâ”€Dataset                        # æ•°æ®é›†ç›®å½•
â”‚  â””â”€img                         # åŸå§‹å›¾åƒæ–‡ä»¶ç›®å½•
â”‚      â”œâ”€000001.jpg              # å›¾åƒæ ·æœ¬
â”‚      â”œâ”€000002.jpg
â”‚      â””â”€...                     # æ›´å¤šå›¾åƒæ ·æœ¬
â”‚  â”œâ”€list_attr.txt               # æ‰€æœ‰å›¾åƒå¯¹åº”çš„å±æ€§æ ‡ç­¾åˆ—è¡¨ï¼ˆå¤šæ ‡ç­¾ï¼‰
â”‚  â”œâ”€list_partition_1000.txt     # åˆ’åˆ†å‡ºçš„å‰1000å¼ å›¾åƒçš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•ç´¢å¼•
â”‚  â”œâ”€list_partition_2000.txt     # å‰2000å¼ å›¾åƒçš„åˆ’åˆ†ç´¢å¼•
â”‚  â”œâ”€list_partition_3000.txt     # å‰3000å¼ å›¾åƒçš„åˆ’åˆ†ç´¢å¼•
â”‚  â””â”€readme.md                   # æ•°æ®é›†è¯´æ˜æ–‡æ¡£
â”œâ”€Log                            # æ—¥å¿—æ–‡ä»¶å¤¹ï¼ˆè®­ç»ƒè¿‡ç¨‹è®°å½•ä¸TensorBoardæ—¥å¿—ï¼‰
â”‚  â””â”€Board                       # TensorBoard å¯è§†åŒ–æ—¥å¿—
â”‚      â”œâ”€MobileNet-1000-0.25    # 1000å›¾åƒÎ±=0.25è®­ç»ƒçš„TensorBoardè®°å½•
â”‚      â”œâ”€MobileNet-1000-0.50    # 1000å›¾åƒÎ±=0.50è®­ç»ƒçš„TensorBoardè®°å½•
â”‚      â”œâ”€MobileNet-1000-1.00    # 1000å›¾åƒÎ±=1.00è®­ç»ƒçš„TensorBoardè®°å½•
â”‚      â”œâ”€MobileNet-2000          # 2000å›¾åƒÎ±=1.00è®­ç»ƒçš„TensorBoardè®°å½•
â”‚      â”œâ”€MobileNet-3000
â”‚      â””â”€MobileNet-3000-lr-damp # é™å­¦ä¹ ç‡ç‰ˆæœ¬çš„è®­ç»ƒè®°å½•
â”‚  â”œâ”€console.log                 # è®­ç»ƒæœŸé—´çš„æ§åˆ¶å°è¾“å‡ºæ—¥å¿—
â”‚  â””â”€train.log                   # æ¯è½®è®­ç»ƒä¸éªŒè¯ç»“æœçš„æ—¥å¿—
â”œâ”€Model                          # æ¨¡å‹ä¿å­˜ç›®å½•
â”‚  â””â”€MobileNet                   # MobileNetæ¨¡å‹æƒé‡å­˜å‚¨
â”‚      â”œâ”€best_model.pth          # è¡¨ç°æœ€ä¼˜çš„æ¨¡å‹å‚æ•°
â”‚      â”œâ”€Epoch5_20250616_190701.pth  # ç¬¬5è½®ä¿å­˜çš„æ¨¡å‹ï¼ˆæ—¶é—´æˆ³å‘½åï¼‰
â”‚      â”œâ”€Epoch10_20250616_190932.pth
â”‚      â””â”€...                     # æ›´å¤šè®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ¨¡å‹
â”œâ”€Util                           # å·¥å…·è„šæœ¬ç›®å½•
â”‚  â”œâ”€Deal_Label.py               # æ ‡ç­¾æ–‡ä»¶çš„å¤„ç†ï¼ˆæ¸…æ´—ã€æ ¼å¼è½¬æ¢ï¼‰
â”‚  â”œâ”€Load_Dataset.py             # åŠ è½½æ•°æ®é›†ä¸åˆ’åˆ†æ•°æ®
â”‚  â”œâ”€Model.py                    # ç½‘ç»œç»“æ„å®šä¹‰ï¼ˆMobileNetV2 åŠè¾…åŠ©æ¨¡å—ï¼‰
â”‚  â”œâ”€New_Partition.py            # ç”Ÿæˆæ–°çš„æ•°æ®åˆ’åˆ†åˆ—è¡¨
â”‚  â””â”€Visualize_Feature.py        # ç‰¹å¾å›¾çš„å¯è§†åŒ–æ–¹æ³•
â”œâ”€.env                           # ç¯å¢ƒå˜é‡é…ç½®ï¼ˆç”¨äºæœ¬åœ°å¼€å‘ï¼‰
â”œâ”€Config.yaml                    # é¡¹ç›®å‚æ•°é…ç½®æ–‡ä»¶ï¼ˆå¦‚æ–‡ä»¶è·¯å¾„ã€å­¦ä¹ ç‡ç­‰ï¼‰
â”œâ”€readme.md                      # é¡¹ç›®è¯´æ˜æ–‡æ¡£ï¼ˆåŠŸèƒ½ä»‹ç»ã€è¿è¡Œæ–¹å¼ç­‰ï¼‰
â”œâ”€requirements.txt              # Pythonä¾èµ–åº“æ¸…å•
â”œâ”€Test.py                        # æ¨¡å‹æµ‹è¯•ä¸è¯„ä¼°è„šæœ¬
â””â”€Train.py                       # ä¸»è®­ç»ƒç¨‹åº
```

## ğŸš€Usage
### 1.Prepare Data
Ensure your dataset is organized as described above. Update the file paths in config.yaml.
### 2.Train the Model
```bash
python Train.py
```
Training logs and TensorBoard summaries will be saved in Log/.
### 3.Visualize Training Metrics
Start TensorBoard:
```bash
tensorboard --logdir Log/Board
```
Open `http://localhost:6006` in your browser to view training curves.
### 4.Test the Model
- Run testing on the test set:
```bash
python Test.py
```
- Or predict a single image's attributes:
```bash
python Test.py --img Dataset/img/000010.jpg
```
## âš™Configuration
The config.yaml file contains key configuration parameters:
```yaml
# Dir
IMG_DIR: Dataset/img
MODEL_DIR: Model/MobileNet

# Path
LABEL_PATH: Dataset/list_attr.txt
PARTITION_PATH: Dataset/list_partition_3000.txt
LOG_PATH: Log/train.log

# Attributesï¼ˆé»‘å‘ã€çœ¼é•œã€æµ“å¦†ã€ç”·æ€§ã€èƒ¡å­ã€ç™½çš®è‚¤ã€å¾®ç¬‘ã€å·å‘ã€å¸½å­ã€å¹´è½»äººï¼‰ï¼ˆ1ä¸ºactiveï¼Œ-1ä¸ºnegativeï¼‰
ATTRIBUTES: ['Black_Hair', 'Eyeglasses', 'Heavy_Makeup', 'Male', 'Mustache', 'Pale_Skin', 'Smiling', 'Wavy_Hair', 'Wearing_Hat', 'Young']

BATCH_SIZE: 32
IMAGE_SIZE: [218, 178]
NUM_WORKERS: 3

TOTAL_EPOCH: 50
SAVE_FREQUENCE: 5
LEARNING_RATE: 0.001

SAVE_MODEL: False
SAVE_BEST_MODEL: False
SAVE_TO_TENSORBOARD: True
SAVE_LOG: True
RESUME_TRAIN: False
USE_CUDA: True
```

## ğŸ“ˆResult
After training, the system can output prediction vectors representing each attribute with high accuracy. Sample output:
- **Training**:
```bash
     Filename  Black_Hair  Eyeglasses  Heavy_Makeup  Male  Mustache  Pale_Skin  Smiling  Wavy_Hair  Wearing_Hat  Young
0  000001.jpg           0           0             1     0         0          0        1          0            0      1
1  000002.jpg           0           0             0     0         0          0        1          0            0      1
2  000003.jpg           0           0             0     1         0          0        0          1            0      1
3  000004.jpg           0           0             0     0         0          0        0          0            0      1
4  000005.jpg           0           0             1     0         0          0        0          0            0      1
Num_TrainSample: 1600, Num_ValSample: 200, Num_TestSample: 200
Cuda is avilable, Running on Cuda
âœ… Epoch [1/50]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:16<00:00,  3.03it/s] 
Train Loss: 0.4714, Train Acc: 0.7634
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.92s/it] 
Val Loss  : 0.4740, Val Acc  : 0.7690
âœ… Epoch [2/50]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:15<00:00,  3.23it/s] 
Train Loss: 0.4285, Train Acc: 0.7943
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.86s/it] 
Val Loss  : 0.4852, Val Acc  : 0.7965
...
```

- **Testing**:
```bash
Cuda is avilable, Running on Cuda
     Filename  Black_Hair  Eyeglasses  Heavy_Makeup  Male  Mustache  Pale_Skin  Smiling  Wavy_Hair  Wearing_Hat  Young
0  000001.jpg           0           0             1     0         0          0        1          0            0      1
1  000002.jpg           0           0             0     0         0          0        1          0            0      1
2  000003.jpg           0           0             0     1         0          0        0          1            0      1
3  000004.jpg           0           0             0     0         0          0        0          0            0      1
4  000005.jpg           0           0             1     0         0          0        0          0            0      1
Num_TrainSample: 2400, Num_ValSample: 300, Num_TestSample: 300
Resume From Saved: Model/MobileNet\best_model.pth (Epoch: None)
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.28s/it]
Predict Label: [False False False  True False False  True False False False]
Real Label   : [0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
Test Loss  : 0.2952, Test Acc  : 0.9033
```
You can view the training effect intuitively on Tensorboard:
**Change value of alpha:**
![image](https://github.com/user-attachments/assets/401772fb-0729-418c-a9ba-dc4da78f8787)

**Change the number of img:**
![image](https://github.com/user-attachments/assets/0bffbbf9-2863-41a2-8da3-e8903d3d44a7)

**Viridis effect of different layer:**
![4e9431ef6ce0f4f4aecf76931b4b53c1](https://github.com/user-attachments/assets/ebacb931-79a3-4027-ae4a-d440d4dfe162)


## ğŸ™Acknowledgments
- The implementation is based on PyTorch.
- MobileNetV2 was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks.
- Dataset is from CelebA.
